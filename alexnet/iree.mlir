module @AlexNet {
  util.global private @_params.features.0.weight {noinline} = dense_resource<__elided__> : tensor<64x3x11x11xf32>
  util.global private @_params.features.0.bias {noinline} = dense_resource<__elided__> : tensor<64xf32>
  util.global private @_params.features.3.weight {noinline} = dense_resource<__elided__> : tensor<192x64x5x5xf32>
  util.global private @_params.features.3.bias {noinline} = dense_resource<__elided__> : tensor<192xf32>
  util.global private @_params.features.6.weight {noinline} = dense_resource<__elided__> : tensor<384x192x3x3xf32>
  util.global private @_params.features.6.bias {noinline} = dense_resource<__elided__> : tensor<384xf32>
  util.global private @_params.features.8.weight {noinline} = dense_resource<__elided__> : tensor<256x384x3x3xf32>
  util.global private @_params.features.8.bias {noinline} = dense_resource<__elided__> : tensor<256xf32>
  util.global private @_params.features.10.weight {noinline} = dense_resource<__elided__> : tensor<256x256x3x3xf32>
  util.global private @_params.features.10.bias {noinline} = dense_resource<__elided__> : tensor<256xf32>
  util.global private @_params.classifier.1.weight {noinline} = dense_resource<__elided__> : tensor<4096x9216xf32>
  util.global private @_params.classifier.1.bias {noinline} = dense_resource<__elided__> : tensor<4096xf32>
  util.global private @_params.classifier.4.weight {noinline} = dense_resource<__elided__> : tensor<4096x4096xf32>
  util.global private @_params.classifier.4.bias {noinline} = dense_resource<__elided__> : tensor<4096xf32>
  util.global private @_params.classifier.6.weight {noinline} = dense_resource<__elided__> : tensor<1000x4096xf32>
  util.global private @_params.classifier.6.bias {noinline} = dense_resource<__elided__> : tensor<1000xf32>
  func.func @main(%arg0: tensor<64x3x224x224xf32>) -> tensor<64x1000xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<64x3x224x224xf32> -> !torch.vtensor<[64,3,224,224],f32>
    %1 = call @forward(%0) : (!torch.vtensor<[64,3,224,224],f32>) -> !torch.vtensor<[64,1000],f32>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[64,1000],f32> -> tensor<64x1000xf32>
    return %2 : tensor<64x1000xf32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[64,3,224,224],f32>) -> !torch.vtensor<[64,1000],f32> {
    %_params.features.0.weight = util.global.load @_params.features.0.weight : tensor<64x3x11x11xf32>
    %0 = torch_c.from_builtin_tensor %_params.features.0.weight : tensor<64x3x11x11xf32> -> !torch.vtensor<[64,3,11,11],f32>
    %_params.features.0.bias = util.global.load @_params.features.0.bias : tensor<64xf32>
    %1 = torch_c.from_builtin_tensor %_params.features.0.bias : tensor<64xf32> -> !torch.vtensor<[64],f32>
    %int4 = torch.constant.int 4
    %int4_0 = torch.constant.int 4
    %2 = torch.prim.ListConstruct %int4, %int4_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int2 = torch.constant.int 2
    %int2_1 = torch.constant.int 2
    %3 = torch.prim.ListConstruct %int2, %int2_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1 = torch.constant.int 1
    %int1_2 = torch.constant.int 1
    %4 = torch.prim.ListConstruct %int1, %int1_2 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0 = torch.constant.int 0
    %int0_3 = torch.constant.int 0
    %5 = torch.prim.ListConstruct %int0, %int0_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_4 = torch.constant.int 1
    %6 = torch.aten.convolution %arg0, %0, %1, %2, %3, %4, %false, %5, %int1_4 : !torch.vtensor<[64,3,224,224],f32>, !torch.vtensor<[64,3,11,11],f32>, !torch.vtensor<[64],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[64,64,55,55],f32>
    %7 = torch.aten.relu %6 : !torch.vtensor<[64,64,55,55],f32> -> !torch.vtensor<[64,64,55,55],f32>
    %8 = torch.aten.detach %7 : !torch.vtensor<[64,64,55,55],f32> -> !torch.vtensor<[64,64,55,55],f32>
    %int3 = torch.constant.int 3
    %int3_5 = torch.constant.int 3
    %9 = torch.prim.ListConstruct %int3, %int3_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int2_6 = torch.constant.int 2
    %int2_7 = torch.constant.int 2
    %10 = torch.prim.ListConstruct %int2_6, %int2_7 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_8 = torch.constant.int 0
    %int0_9 = torch.constant.int 0
    %11 = torch.prim.ListConstruct %int0_8, %int0_9 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_10 = torch.constant.int 1
    %int1_11 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_10, %int1_11 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_12 = torch.constant.bool false
    %result0, %result1 = torch.aten.max_pool2d_with_indices %7, %9, %10, %11, %12, %false_12 : !torch.vtensor<[64,64,55,55],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool -> !torch.vtensor<[64,64,27,27],f32>, !torch.vtensor<[64,64,27,27],si64>
    %_params.features.3.weight = util.global.load @_params.features.3.weight : tensor<192x64x5x5xf32>
    %13 = torch_c.from_builtin_tensor %_params.features.3.weight : tensor<192x64x5x5xf32> -> !torch.vtensor<[192,64,5,5],f32>
    %_params.features.3.bias = util.global.load @_params.features.3.bias : tensor<192xf32>
    %14 = torch_c.from_builtin_tensor %_params.features.3.bias : tensor<192xf32> -> !torch.vtensor<[192],f32>
    %int1_13 = torch.constant.int 1
    %int1_14 = torch.constant.int 1
    %15 = torch.prim.ListConstruct %int1_13, %int1_14 : (!torch.int, !torch.int) -> !torch.list<int>
    %int2_15 = torch.constant.int 2
    %int2_16 = torch.constant.int 2
    %16 = torch.prim.ListConstruct %int2_15, %int2_16 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_17 = torch.constant.int 1
    %int1_18 = torch.constant.int 1
    %17 = torch.prim.ListConstruct %int1_17, %int1_18 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_19 = torch.constant.bool false
    %int0_20 = torch.constant.int 0
    %int0_21 = torch.constant.int 0
    %18 = torch.prim.ListConstruct %int0_20, %int0_21 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_22 = torch.constant.int 1
    %19 = torch.aten.convolution %result0, %13, %14, %15, %16, %17, %false_19, %18, %int1_22 : !torch.vtensor<[64,64,27,27],f32>, !torch.vtensor<[192,64,5,5],f32>, !torch.vtensor<[192],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[64,192,27,27],f32>
    %20 = torch.aten.relu %19 : !torch.vtensor<[64,192,27,27],f32> -> !torch.vtensor<[64,192,27,27],f32>
    %21 = torch.aten.detach %20 : !torch.vtensor<[64,192,27,27],f32> -> !torch.vtensor<[64,192,27,27],f32>
    %int3_23 = torch.constant.int 3
    %int3_24 = torch.constant.int 3
    %22 = torch.prim.ListConstruct %int3_23, %int3_24 : (!torch.int, !torch.int) -> !torch.list<int>
    %int2_25 = torch.constant.int 2
    %int2_26 = torch.constant.int 2
    %23 = torch.prim.ListConstruct %int2_25, %int2_26 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_27 = torch.constant.int 0
    %int0_28 = torch.constant.int 0
    %24 = torch.prim.ListConstruct %int0_27, %int0_28 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_29 = torch.constant.int 1
    %int1_30 = torch.constant.int 1
    %25 = torch.prim.ListConstruct %int1_29, %int1_30 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_31 = torch.constant.bool false
    %result0_32, %result1_33 = torch.aten.max_pool2d_with_indices %20, %22, %23, %24, %25, %false_31 : !torch.vtensor<[64,192,27,27],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool -> !torch.vtensor<[64,192,13,13],f32>, !torch.vtensor<[64,192,13,13],si64>
    %_params.features.6.weight = util.global.load @_params.features.6.weight : tensor<384x192x3x3xf32>
    %26 = torch_c.from_builtin_tensor %_params.features.6.weight : tensor<384x192x3x3xf32> -> !torch.vtensor<[384,192,3,3],f32>
    %_params.features.6.bias = util.global.load @_params.features.6.bias : tensor<384xf32>
    %27 = torch_c.from_builtin_tensor %_params.features.6.bias : tensor<384xf32> -> !torch.vtensor<[384],f32>
    %int1_34 = torch.constant.int 1
    %int1_35 = torch.constant.int 1
    %28 = torch.prim.ListConstruct %int1_34, %int1_35 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_36 = torch.constant.int 1
    %int1_37 = torch.constant.int 1
    %29 = torch.prim.ListConstruct %int1_36, %int1_37 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_38 = torch.constant.int 1
    %int1_39 = torch.constant.int 1
    %30 = torch.prim.ListConstruct %int1_38, %int1_39 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_40 = torch.constant.bool false
    %int0_41 = torch.constant.int 0
    %int0_42 = torch.constant.int 0
    %31 = torch.prim.ListConstruct %int0_41, %int0_42 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_43 = torch.constant.int 1
    %32 = torch.aten.convolution %result0_32, %26, %27, %28, %29, %30, %false_40, %31, %int1_43 : !torch.vtensor<[64,192,13,13],f32>, !torch.vtensor<[384,192,3,3],f32>, !torch.vtensor<[384],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[64,384,13,13],f32>
    %33 = torch.aten.relu %32 : !torch.vtensor<[64,384,13,13],f32> -> !torch.vtensor<[64,384,13,13],f32>
    %34 = torch.aten.detach %33 : !torch.vtensor<[64,384,13,13],f32> -> !torch.vtensor<[64,384,13,13],f32>
    %_params.features.8.weight = util.global.load @_params.features.8.weight : tensor<256x384x3x3xf32>
    %35 = torch_c.from_builtin_tensor %_params.features.8.weight : tensor<256x384x3x3xf32> -> !torch.vtensor<[256,384,3,3],f32>
    %_params.features.8.bias = util.global.load @_params.features.8.bias : tensor<256xf32>
    %36 = torch_c.from_builtin_tensor %_params.features.8.bias : tensor<256xf32> -> !torch.vtensor<[256],f32>
    %int1_44 = torch.constant.int 1
    %int1_45 = torch.constant.int 1
    %37 = torch.prim.ListConstruct %int1_44, %int1_45 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_46 = torch.constant.int 1
    %int1_47 = torch.constant.int 1
    %38 = torch.prim.ListConstruct %int1_46, %int1_47 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_48 = torch.constant.int 1
    %int1_49 = torch.constant.int 1
    %39 = torch.prim.ListConstruct %int1_48, %int1_49 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_50 = torch.constant.bool false
    %int0_51 = torch.constant.int 0
    %int0_52 = torch.constant.int 0
    %40 = torch.prim.ListConstruct %int0_51, %int0_52 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_53 = torch.constant.int 1
    %41 = torch.aten.convolution %33, %35, %36, %37, %38, %39, %false_50, %40, %int1_53 : !torch.vtensor<[64,384,13,13],f32>, !torch.vtensor<[256,384,3,3],f32>, !torch.vtensor<[256],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[64,256,13,13],f32>
    %42 = torch.aten.relu %41 : !torch.vtensor<[64,256,13,13],f32> -> !torch.vtensor<[64,256,13,13],f32>
    %43 = torch.aten.detach %42 : !torch.vtensor<[64,256,13,13],f32> -> !torch.vtensor<[64,256,13,13],f32>
    %_params.features.10.weight = util.global.load @_params.features.10.weight : tensor<256x256x3x3xf32>
    %44 = torch_c.from_builtin_tensor %_params.features.10.weight : tensor<256x256x3x3xf32> -> !torch.vtensor<[256,256,3,3],f32>
    %_params.features.10.bias = util.global.load @_params.features.10.bias : tensor<256xf32>
    %45 = torch_c.from_builtin_tensor %_params.features.10.bias : tensor<256xf32> -> !torch.vtensor<[256],f32>
    %int1_54 = torch.constant.int 1
    %int1_55 = torch.constant.int 1
    %46 = torch.prim.ListConstruct %int1_54, %int1_55 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_56 = torch.constant.int 1
    %int1_57 = torch.constant.int 1
    %47 = torch.prim.ListConstruct %int1_56, %int1_57 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_58 = torch.constant.int 1
    %int1_59 = torch.constant.int 1
    %48 = torch.prim.ListConstruct %int1_58, %int1_59 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_60 = torch.constant.bool false
    %int0_61 = torch.constant.int 0
    %int0_62 = torch.constant.int 0
    %49 = torch.prim.ListConstruct %int0_61, %int0_62 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_63 = torch.constant.int 1
    %50 = torch.aten.convolution %42, %44, %45, %46, %47, %48, %false_60, %49, %int1_63 : !torch.vtensor<[64,256,13,13],f32>, !torch.vtensor<[256,256,3,3],f32>, !torch.vtensor<[256],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[64,256,13,13],f32>
    %51 = torch.aten.relu %50 : !torch.vtensor<[64,256,13,13],f32> -> !torch.vtensor<[64,256,13,13],f32>
    %52 = torch.aten.detach %51 : !torch.vtensor<[64,256,13,13],f32> -> !torch.vtensor<[64,256,13,13],f32>
    %int3_64 = torch.constant.int 3
    %int3_65 = torch.constant.int 3
    %53 = torch.prim.ListConstruct %int3_64, %int3_65 : (!torch.int, !torch.int) -> !torch.list<int>
    %int2_66 = torch.constant.int 2
    %int2_67 = torch.constant.int 2
    %54 = torch.prim.ListConstruct %int2_66, %int2_67 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_68 = torch.constant.int 0
    %int0_69 = torch.constant.int 0
    %55 = torch.prim.ListConstruct %int0_68, %int0_69 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_70 = torch.constant.int 1
    %int1_71 = torch.constant.int 1
    %56 = torch.prim.ListConstruct %int1_70, %int1_71 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_72 = torch.constant.bool false
    %result0_73, %result1_74 = torch.aten.max_pool2d_with_indices %51, %53, %54, %55, %56, %false_72 : !torch.vtensor<[64,256,13,13],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool -> !torch.vtensor<[64,256,6,6],f32>, !torch.vtensor<[64,256,6,6],si64>
    %int1_75 = torch.constant.int 1
    %int1_76 = torch.constant.int 1
    %57 = torch.prim.ListConstruct %int1_75, %int1_76 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_77 = torch.constant.int 1
    %int1_78 = torch.constant.int 1
    %58 = torch.prim.ListConstruct %int1_77, %int1_78 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_79 = torch.constant.int 0
    %int0_80 = torch.constant.int 0
    %59 = torch.prim.ListConstruct %int0_79, %int0_80 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_81 = torch.constant.bool false
    %true = torch.constant.bool true
    %none = torch.constant.none
    %60 = torch.aten.avg_pool2d %result0_73, %57, %58, %59, %false_81, %true, %none : !torch.vtensor<[64,256,6,6],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.bool, !torch.none -> !torch.vtensor<[64,256,6,6],f32>
    %int64 = torch.constant.int 64
    %int9216 = torch.constant.int 9216
    %61 = torch.prim.ListConstruct %int64, %int9216 : (!torch.int, !torch.int) -> !torch.list<int>
    %62 = torch.aten.view %60, %61 : !torch.vtensor<[64,256,6,6],f32>, !torch.list<int> -> !torch.vtensor<[64,9216],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %true_82 = torch.constant.bool true
    %result0_83, %result1_84 = torch.aten.native_dropout %62, %float5.000000e-01, %true_82 : !torch.vtensor<[64,9216],f32>, !torch.float, !torch.bool -> !torch.vtensor<[64,9216],f32>, !torch.vtensor<[64,9216],i1>
    %_params.classifier.1.weight = util.global.load @_params.classifier.1.weight : tensor<4096x9216xf32>
    %63 = torch_c.from_builtin_tensor %_params.classifier.1.weight : tensor<4096x9216xf32> -> !torch.vtensor<[4096,9216],f32>
    %int0_85 = torch.constant.int 0
    %int1_86 = torch.constant.int 1
    %64 = torch.aten.transpose.int %63, %int0_85, %int1_86 : !torch.vtensor<[4096,9216],f32>, !torch.int, !torch.int -> !torch.vtensor<[9216,4096],f32>
    %65 = torch.aten.mm %result0_83, %64 : !torch.vtensor<[64,9216],f32>, !torch.vtensor<[9216,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %int1_87 = torch.constant.int 1
    %66 = torch.aten.mul.Scalar %65, %int1_87 : !torch.vtensor<[64,4096],f32>, !torch.int -> !torch.vtensor<[64,4096],f32>
    %_params.classifier.1.bias = util.global.load @_params.classifier.1.bias : tensor<4096xf32>
    %67 = torch_c.from_builtin_tensor %_params.classifier.1.bias : tensor<4096xf32> -> !torch.vtensor<[4096],f32>
    %int1_88 = torch.constant.int 1
    %68 = torch.aten.mul.Scalar %67, %int1_88 : !torch.vtensor<[4096],f32>, !torch.int -> !torch.vtensor<[4096],f32>
    %int1_89 = torch.constant.int 1
    %69 = torch.aten.add.Tensor %66, %68, %int1_89 : !torch.vtensor<[64,4096],f32>, !torch.vtensor<[4096],f32>, !torch.int -> !torch.vtensor<[64,4096],f32>
    %70 = torch.aten.relu %69 : !torch.vtensor<[64,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %71 = torch.aten.detach %70 : !torch.vtensor<[64,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %float5.000000e-01_90 = torch.constant.float 5.000000e-01
    %true_91 = torch.constant.bool true
    %result0_92, %result1_93 = torch.aten.native_dropout %70, %float5.000000e-01_90, %true_91 : !torch.vtensor<[64,4096],f32>, !torch.float, !torch.bool -> !torch.vtensor<[64,4096],f32>, !torch.vtensor<[64,4096],i1>
    %_params.classifier.4.weight = util.global.load @_params.classifier.4.weight : tensor<4096x4096xf32>
    %72 = torch_c.from_builtin_tensor %_params.classifier.4.weight : tensor<4096x4096xf32> -> !torch.vtensor<[4096,4096],f32>
    %int0_94 = torch.constant.int 0
    %int1_95 = torch.constant.int 1
    %73 = torch.aten.transpose.int %72, %int0_94, %int1_95 : !torch.vtensor<[4096,4096],f32>, !torch.int, !torch.int -> !torch.vtensor<[4096,4096],f32>
    %74 = torch.aten.mm %result0_92, %73 : !torch.vtensor<[64,4096],f32>, !torch.vtensor<[4096,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %int1_96 = torch.constant.int 1
    %75 = torch.aten.mul.Scalar %74, %int1_96 : !torch.vtensor<[64,4096],f32>, !torch.int -> !torch.vtensor<[64,4096],f32>
    %_params.classifier.4.bias = util.global.load @_params.classifier.4.bias : tensor<4096xf32>
    %76 = torch_c.from_builtin_tensor %_params.classifier.4.bias : tensor<4096xf32> -> !torch.vtensor<[4096],f32>
    %int1_97 = torch.constant.int 1
    %77 = torch.aten.mul.Scalar %76, %int1_97 : !torch.vtensor<[4096],f32>, !torch.int -> !torch.vtensor<[4096],f32>
    %int1_98 = torch.constant.int 1
    %78 = torch.aten.add.Tensor %75, %77, %int1_98 : !torch.vtensor<[64,4096],f32>, !torch.vtensor<[4096],f32>, !torch.int -> !torch.vtensor<[64,4096],f32>
    %79 = torch.aten.relu %78 : !torch.vtensor<[64,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %80 = torch.aten.detach %79 : !torch.vtensor<[64,4096],f32> -> !torch.vtensor<[64,4096],f32>
    %_params.classifier.6.weight = util.global.load @_params.classifier.6.weight : tensor<1000x4096xf32>
    %81 = torch_c.from_builtin_tensor %_params.classifier.6.weight : tensor<1000x4096xf32> -> !torch.vtensor<[1000,4096],f32>
    %int0_99 = torch.constant.int 0
    %int1_100 = torch.constant.int 1
    %82 = torch.aten.transpose.int %81, %int0_99, %int1_100 : !torch.vtensor<[1000,4096],f32>, !torch.int, !torch.int -> !torch.vtensor<[4096,1000],f32>
    %83 = torch.aten.mm %79, %82 : !torch.vtensor<[64,4096],f32>, !torch.vtensor<[4096,1000],f32> -> !torch.vtensor<[64,1000],f32>
    %int1_101 = torch.constant.int 1
    %84 = torch.aten.mul.Scalar %83, %int1_101 : !torch.vtensor<[64,1000],f32>, !torch.int -> !torch.vtensor<[64,1000],f32>
    %_params.classifier.6.bias = util.global.load @_params.classifier.6.bias : tensor<1000xf32>
    %85 = torch_c.from_builtin_tensor %_params.classifier.6.bias : tensor<1000xf32> -> !torch.vtensor<[1000],f32>
    %int1_102 = torch.constant.int 1
    %86 = torch.aten.mul.Scalar %85, %int1_102 : !torch.vtensor<[1000],f32>, !torch.int -> !torch.vtensor<[1000],f32>
    %int1_103 = torch.constant.int 1
    %87 = torch.aten.add.Tensor %84, %86, %int1_103 : !torch.vtensor<[64,1000],f32>, !torch.vtensor<[1000],f32>, !torch.int -> !torch.vtensor<[64,1000],f32>
    return %87 : !torch.vtensor<[64,1000],f32>
  }
}
